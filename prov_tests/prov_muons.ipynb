{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of provenance\n",
    "\n",
    "## Objective\n",
    "- The goal of this test is to have an idea of the existing tools to implement the provenance in a program of CTA using the ctapipe library\n",
    "\n",
    "## Context\n",
    "- This test is done with the muon_reconstruction.py program \n",
    "- This program uses Karl ctapipe and provenance modules/libraries (v. 0.5.2.post756+git93dae3f - feature/improve-tool branch on https://github.com/kosack/ctapipe)\n",
    "- The Provenance database is defined in memory and accessed with the sqlalchemy library\n",
    "\n",
    "## Structure of the notebook\n",
    "- Definition the Provenance database structure\n",
    "- Definition of the muon_reconstruction tool\n",
    "- Addition of the muon_reconstruction (named ctapipe_display_muons) activity description in the provenance database\n",
    "- Execution of the muon_reconstruction program\n",
    "- Addition of the provenance information of the job in the database\n",
    "- Query the provenance database and store the result in a file\n",
    "- Vizualisation of the provenance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Provenance database structure\n",
    "\n",
    "#### Provenance Data Model PR2 2019-07-19\n",
    "<img src=\"2019-07-19_PR2_PROV_Fig8.png\">\n",
    "\n",
    "#### Remarks\n",
    "- Activity\n",
    "    Activity.activityDescription = concat(activity_name, '_', ctapipe_version)\n",
    "    Dates are curreuntly stored as strings\n",
    "- Entity\n",
    "    Entity.id = hash(file)\n",
    "    Inheritance is implemented as joined table inheritance (dependant tables) => addition of the classType attribute in the Entity and EntityDescription classes\n",
    "- Relations\n",
    "    Used.id, WasGeneratedBy.id, WasAttributedTo.id, WasAssociatedWith.id are interger and autoincremented\n",
    "- A lot of empty fields and problem to associate Entity with EntityDescription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from provenanceDB import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## muon_reconstruction definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example to load raw data (hessio format), calibrate and reconstruct muon\n",
    "ring parameters, and write the muon ring and intensity parameters to an output\n",
    "table.\n",
    "\n",
    "The resulting output can be read e.g. using `pandas.read_hdf(filename,\n",
    "'muons/LSTCam')`\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ctapipe.calib import CameraCalibrator\n",
    "from ctapipe.core import Provenance\n",
    "from ctapipe.core import Tool, ToolConfigurationError\n",
    "from ctapipe.core import traits as t\n",
    "from ctapipe.image.muon.muon_diagnostic_plots import plot_muon_event\n",
    "from ctapipe.image.muon.muon_reco_functions import analyze_muon_event\n",
    "from ctapipe.io import EventSource, event_source\n",
    "from ctapipe.io import HDF5TableWriter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Supresses iminuit warnings\n",
    "\n",
    "\n",
    "def _exclude_some_columns(subarray, writer):\n",
    "    \"\"\" a hack to exclude some columns of all output tables here we exclude\n",
    "    the prediction and mask quantities, since they are arrays and thus not\n",
    "    readable by pandas.  Also, prediction currently is a variable-length\n",
    "    quantity (need to change it to be fixed-length), so it cannot be written\n",
    "    to a fixed-length table.\n",
    "    \"\"\"\n",
    "    all_camids = {str(x.camera) for x in subarray.tel.values()}\n",
    "    for cam in all_camids:\n",
    "        writer.exclude(cam, 'prediction')\n",
    "        writer.exclude(cam, 'mask')\n",
    "\n",
    "class MuonDisplayerTool(Tool):\n",
    "    name = 'ctapipe-reconstruct-muons'\n",
    "    description = t.Unicode(__doc__)\n",
    "\n",
    "    events = t.Unicode(\"\",\n",
    "                       help=\"input event data file\").tag(config=True)\n",
    "\n",
    "    outfile = t.Unicode(\"muons.hdf5\", help='HDF5 output file name').tag(\n",
    "        config=True)\n",
    "\n",
    "    display = t.Bool(\n",
    "        help='display the camera events', default=False\n",
    "    ).tag(config=True)\n",
    "\n",
    "    classes = t.List([\n",
    "        CameraCalibrator, EventSource\n",
    "    ])\n",
    "\n",
    "    aliases = t.Dict({\n",
    "        'input': 'MuonDisplayerTool.events',\n",
    "        'outfile': 'MuonDisplayerTool.outfile',\n",
    "        'display': 'MuonDisplayerTool.display',\n",
    "        'max_events': 'EventSource.max_events',\n",
    "        'allowed_tels': 'EventSource.allowed_tels',\n",
    "    })\n",
    "\n",
    "    def setup(self):\n",
    "        if self.events == '':\n",
    "            raise ToolConfigurationError(\"please specify --input <events file>\")\n",
    "        self.log.debug(\"input: %s\", self.events)\n",
    "        self.source = event_source(self.events)\n",
    "        self.calib = CameraCalibrator(parent=self)\n",
    "        self.writer = HDF5TableWriter(self.outfile, \"muons\")\n",
    "\n",
    "    def start(self):\n",
    "\n",
    "        numev = 0\n",
    "        self.num_muons_found = defaultdict(int)\n",
    "\n",
    "        for event in tqdm(self.source, desc='detecting muons'):\n",
    "\n",
    "            self.calib(event)\n",
    "            muon_evt = analyze_muon_event(event)\n",
    "\n",
    "            if numev == 0:\n",
    "                _exclude_some_columns(event.inst.subarray, self.writer)\n",
    "\n",
    "            numev += 1\n",
    "\n",
    "            if not muon_evt['MuonIntensityParams']:\n",
    "                # No telescopes  contained a good muon\n",
    "                continue\n",
    "            else:\n",
    "                if self.display:\n",
    "                    plot_muon_event(event, muon_evt)\n",
    "\n",
    "                for tel_id in muon_evt['TelIds']:\n",
    "                    idx = muon_evt['TelIds'].index(tel_id)\n",
    "                    intens_params = muon_evt['MuonIntensityParams'][idx]\n",
    "\n",
    "                    if intens_params is not None:\n",
    "                        ring_params = muon_evt['MuonRingParams'][idx]\n",
    "                        cam_id = str(event.inst.subarray.tel[tel_id].camera)\n",
    "                        self.num_muons_found[cam_id] += 1\n",
    "                        self.log.debug(\"INTENSITY: %s\", intens_params)\n",
    "                        self.log.debug(\"RING: %s\", ring_params)\n",
    "                        self.writer.write(table_name=cam_id,\n",
    "                                          containers=[intens_params,\n",
    "                                                      ring_params])\n",
    "\n",
    "                self.log.info(\n",
    "                    \"Event Number: %d, found %s muons\",\n",
    "                    numev, dict(self.num_muons_found)\n",
    "                )\n",
    "\n",
    "    def finish(self):\n",
    "        Provenance().add_output_file(self.outfile,\n",
    "                                     role='dl1.tel.evt.muon')\n",
    "        self.writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptions added in the Provenance database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 11:44:47,690 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2019-08-01 11:44:47,691 INFO sqlalchemy.engine.base.Engine INSERT INTO \"activityDescriptions\" (id, name, version, description, type, subtype, doculink) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:44:47,692 INFO sqlalchemy.engine.base.Engine ('ctapipe_display_muons_0.6.1', 'ctapipe_display_muons', '0.6.1', None, 'reconstruction', '', '')\n",
      "2019-08-01 11:44:47,695 INFO sqlalchemy.engine.base.Engine INSERT INTO \"entityDescriptions\" (id, name, type, description, doculink, \"classType\") VALUES (?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:44:47,695 INFO sqlalchemy.engine.base.Engine (('proton_events', 'protons', None, 'proton file', None, 'datasetDescription'), ('muons_hdf5', 'muons', None, 'muon file', None, 'datasetDescription'), ('status', None, None, None, None, 'valueDescription'))\n",
      "2019-08-01 11:44:47,697 INFO sqlalchemy.engine.base.Engine INSERT INTO \"valueDescriptions\" (id, \"valueType\", unit, ucd, utype, min, max, \"default\", options) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:44:47,698 INFO sqlalchemy.engine.base.Engine ('status', None, None, None, None, None, None, None, None)\n",
      "2019-08-01 11:44:47,703 INFO sqlalchemy.engine.base.Engine INSERT INTO \"datasetDescriptions\" (id, \"contentType\") VALUES (?, ?)\n",
      "2019-08-01 11:44:47,705 INFO sqlalchemy.engine.base.Engine (('proton_events', None), ('muons_hdf5', None))\n",
      "2019-08-01 11:44:47,709 INFO sqlalchemy.engine.base.Engine INSERT INTO \"usageDescriptions\" (id, role, description, type, multiplicity, \"activityDescription_id\", \"entityDescription_id\") VALUES (?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:44:47,710 INFO sqlalchemy.engine.base.Engine ('ctapipe_display_muons_0.6.1_proton_events', 'dl0.sub.evt', None, None, None, 'ctapipe_display_muons_0.6.1', 'proton_events')\n",
      "2019-08-01 11:44:47,712 INFO sqlalchemy.engine.base.Engine INSERT INTO \"generationDescriptions\" (id, role, description, type, multiplicity, \"activityDescription_id\", \"entityDescription_id\") VALUES (?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:44:47,713 INFO sqlalchemy.engine.base.Engine (('ctapipe_display_muons_0.6.1_muons_hdf5', 'dl0.sub.evt', None, None, None, 'ctapipe_display_muons_0.6.1', 'muons_hdf5'), ('ctapipe_display_muons_0.6.1_status', 'quality', None, None, None, 'ctapipe_display_muons_0.6.1', 'status'))\n",
      "2019-08-01 11:44:47,714 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# Define the session to talk to the database\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Create an instance of ActivityDescription \n",
    "actDesc1 = ActivityDescription(id='ctapipe_display_muons_0.6.1',name='ctapipe_display_muons',\\\n",
    "                               type='reconstruction',subtype='',version='0.6.1', doculink='')\n",
    "\n",
    "# Create the description of input entities\n",
    "dataDesc1 = DatasetDescription(id='proton_events', name='protons', description='proton file', classType='datasetDescription')\n",
    "usedDesc1 = UsageDescription(id='ctapipe_display_muons_0.6.1_proton_events',activityDescription=actDesc1, entityDescription=dataDesc1, role=\"dl0.sub.evt\")\n",
    "# Create the description of output entities\n",
    "dataDesc2  = DatasetDescription(id='muons_hdf5', name='muons', description='muon file', classType='datasetDescription')\n",
    "wGBDesc1   = GenerationDescription(id='ctapipe_display_muons_0.6.1_muons_hdf5',activityDescription=actDesc1, entityDescription=dataDesc2, role=\"dl0.sub.evt\")\n",
    "valueDesc1 = ValueDescription(id='status', classType='valueDescription')\n",
    "wGBDesc2   = GenerationDescription(id='ctapipe_display_muons_0.6.1_status', activityDescription=actDesc1, entityDescription=valueDesc1, role=\"quality\")\n",
    "\n",
    "# Put the instance in the database\n",
    "session.add(actDesc1)\n",
    "session.add(dataDesc1)\n",
    "session.add(usedDesc1)\n",
    "session.add(dataDesc2)\n",
    "session.add(wGBDesc1)\n",
    "session.add(valueDesc1)\n",
    "session.add(wGBDesc2)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run muon_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mINFO\u001b[0m [MuonDisplayerTool] (tool/initialize): ctapipe version 0.5.2.post756+git93dae3f\n",
      "\u001b[1;32mINFO\u001b[0m [MuonDisplayerTool] (tool/run): Starting: ctapipe-reconstruct-muons\n",
      "\u001b[1;32mINFO\u001b[0m [MuonDisplayerTool] (tool/run): CONFIG: {'MuonDisplayerTool': {'config_file': '', 'display': False, 'events': 'proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz', 'log_datefmt': '%Y-%m-%d %H:%M:%S', 'log_format': '%(levelname)s [%(name)s] (%(module)s/%(funcName)s): %(message)s', 'log_level': 20, 'outfile': 'muons.hdf5'}}\n",
      "detecting muons: 8it [00:02,  3.48it/s]\n",
      "\u001b[1;32mINFO\u001b[0m [MuonDisplayerTool] (tool/run): Finished: ctapipe-reconstruct-muons\n",
      "\u001b[1;32mINFO\u001b[0m [MuonDisplayerTool] (tool/run): Output: /Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/muons.hdf5\n"
     ]
    }
   ],
   "source": [
    "from ctapipe.core import Provenance\n",
    "from pprint import pprint\n",
    "p = Provenance()  # note this is a singleton, so only ever one global provenence object\n",
    "p.clear()\n",
    "\n",
    "p.start_activity()\n",
    "    \n",
    "myTool = MuonDisplayerTool()\n",
    "#myTool.run(['--input=gamma_20deg_180deg_run1000___cta-prod3-demo_desert-2150m-Paranal-demo2rad_cone10.simtel.gz'])\n",
    "#print(myTool.get_current_config())\n",
    "\n",
    "#myTool = MuonDisplayerTool()\n",
    "myTool.run(['--input=proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz'])\n",
    "\n",
    "p.finish_activity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ctapipe-reconstruct-muons',\n",
       " '/Users/bourgeat/anaconda3/envs/cta-dev-improve/bin/python']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.finished_activity_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activity_name': 'ctapipe-reconstruct-muons',\n",
       "  'activity_uuid': '4f0aac5b-8f39-453f-a8f6-9bac806c9fee',\n",
       "  'start': {'time_utc': '2019-08-01T09:44:51.529'},\n",
       "  'stop': {'time_utc': '2019-08-01T09:44:54.396'},\n",
       "  'system': {'ctapipe_version': '0.5.2.post756+git93dae3f',\n",
       "   'ctapipe_resources_version': '0.2.17',\n",
       "   'pyhessio_version': 'not installed',\n",
       "   'eventio_version': '0.20.3',\n",
       "   'ctapipe_svc_path': None,\n",
       "   'executable': '/Users/bourgeat/anaconda3/envs/cta-dev-improve/bin/python',\n",
       "   'platform': {'architecture_bits': '64bit',\n",
       "    'architecture_linkage': '',\n",
       "    'machine': 'x86_64',\n",
       "    'processor': 'i386',\n",
       "    'node': 'pc33.home',\n",
       "    'version': 'Darwin Kernel Version 17.7.0: Wed Apr 24 21:17:24 PDT 2019; root:xnu-4570.71.45~1/RELEASE_X86_64',\n",
       "    'system': 'Darwin',\n",
       "    'release': '17.7.0',\n",
       "    'libcver': ('', ''),\n",
       "    'num_cpus': 8,\n",
       "    'boot_time': '2019-07-15T08:02:08.000'},\n",
       "   'python': {'version_string': '3.7.3 (default, Mar 27 2019, 16:54:48) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]',\n",
       "    'version': ('3', '7', '3'),\n",
       "    'compiler': 'Clang 4.0.1 (tags/RELEASE_401/final)',\n",
       "    'implementation': 'CPython'},\n",
       "   'environment': {'CONDA_DEFAULT_ENV': 'cta-dev-improve',\n",
       "    'CONDA_PREFIX': '/Users/bourgeat/anaconda3/envs/cta-dev-improve',\n",
       "    'CONDA_PYTHON_EXE': '/Users/bourgeat/anaconda3/bin/python',\n",
       "    'CONDA_EXE': '/Users/bourgeat/anaconda3/bin/conda',\n",
       "    'CONDA_PROMPT_MODIFIER': '(cta-dev-improve) ',\n",
       "    'CONDA_SHLVL': '1',\n",
       "    'PATH': '/Users/bourgeat/anaconda3/envs/cta-dev-improve/bin:/Users/bourgeat/anaconda3/envs/cta-dev-improve/bin:/Users/bourgeat/anaconda3/condabin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/Library/TeX/texbin:/opt/X11/bin',\n",
       "    'LD_LIBRARY_PATH': None,\n",
       "    'DYLD_LIBRARY_PATH': None,\n",
       "    'USER': 'bourgeat',\n",
       "    'HOME': '/Users/bourgeat',\n",
       "    'SHELL': '/bin/bash'},\n",
       "   'arguments': ['/Users/bourgeat/anaconda3/envs/cta-dev-improve/lib/python3.7/site-packages/ipykernel_launcher.py',\n",
       "    '-f',\n",
       "    '/Users/bourgeat/Library/Jupyter/runtime/kernel-4de8889c-2f48-4501-9e3b-fe066ed3c418.json'],\n",
       "   'start_time_utc': '2019-08-01T09:44:51.560'},\n",
       "  'input': [{'url': '/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz',\n",
       "    'role': 'dl0.sub.evt'}],\n",
       "  'output': [{'url': '/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/muons.hdf5',\n",
       "    'role': 'dl1.tel.evt.muon'}],\n",
       "  'config': {'MuonDisplayerTool': {'config_file': '',\n",
       "    'display': False,\n",
       "    'events': 'proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz',\n",
       "    'log_datefmt': '%Y-%m-%d %H:%M:%S',\n",
       "    'log_format': '%(levelname)s [%(name)s] (%(module)s/%(funcName)s): %(message)s',\n",
       "    'log_level': 20,\n",
       "    'outfile': 'muons.hdf5'}},\n",
       "  'status': 'completed',\n",
       "  'duration_min': 0.04778333333330664}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.provenance[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provenance database update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 11:45:11,101 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2019-08-01 11:45:11,102 INFO sqlalchemy.engine.base.Engine SELECT count(*) AS count_1 \n",
      "FROM (SELECT agents.id AS agents_id, agents.name AS agents_name, agents.type AS agents_type, agents.email AS agents_email, agents.affiliation AS agents_affiliation, agents.phone AS agents_phone, agents.address AS agents_address, agents.comment AS agents_comment, agents.url AS agents_url \n",
      "FROM agents \n",
      "WHERE agents.id = ?) AS anon_1\n",
      "2019-08-01 11:45:11,103 INFO sqlalchemy.engine.base.Engine ('CTAO',)\n",
      "2019-08-01 11:45:11,110 INFO sqlalchemy.engine.base.Engine INSERT INTO agents (id, name, type, email, affiliation, phone, address, comment, url) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,112 INFO sqlalchemy.engine.base.Engine ('CTAO', 'CTA Observatory', 'Organization', None, None, None, None, None, None)\n",
      "2019-08-01 11:45:11,116 INFO sqlalchemy.engine.base.Engine SELECT count(*) AS count_1 \n",
      "FROM (SELECT activities.id AS activities_id, activities.name AS activities_name, activities.\"startTime\" AS \"activities_startTime\", activities.\"endTime\" AS \"activities_endTime\", activities.comment AS activities_comment, activities.\"activityDescription_id\" AS \"activities_activityDescription_id\" \n",
      "FROM activities \n",
      "WHERE activities.id = ?) AS anon_1\n",
      "2019-08-01 11:45:11,117 INFO sqlalchemy.engine.base.Engine ('4f0aac5b-8f39-453f-a8f6-9bac806c9fee',)\n",
      "2019-08-01 11:45:11,122 INFO sqlalchemy.engine.base.Engine INSERT INTO activities (id, name, \"startTime\", \"endTime\", comment, \"activityDescription_id\") VALUES (?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,123 INFO sqlalchemy.engine.base.Engine ('4f0aac5b-8f39-453f-a8f6-9bac806c9fee', 'ctapipe-reconstruct-muons', '2019-08-01T09:44:51.529', '2019-08-01T09:44:54.396', '', 'ctapipe-reconstruct-muons_0.5.2.post756+git93dae3f')\n",
      "2019-08-01 11:45:11,124 INFO sqlalchemy.engine.base.Engine INSERT INTO \"wasAssociatedWith\" (role, activity, agent) VALUES (?, ?, ?)\n",
      "2019-08-01 11:45:11,125 INFO sqlalchemy.engine.base.Engine (None, '4f0aac5b-8f39-453f-a8f6-9bac806c9fee', 'CTAO')\n",
      "2019-08-01 11:45:11,127 INFO sqlalchemy.engine.base.Engine SELECT count(*) AS count_1 \n",
      "FROM (SELECT \"datasetEntities\".id AS \"datasetEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities JOIN \"datasetEntities\" ON entities.id = \"datasetEntities\".id \n",
      "WHERE \"datasetEntities\".id = ?) AS anon_1\n",
      "2019-08-01 11:45:11,128 INFO sqlalchemy.engine.base.Engine ('7bfa14c7-17af-598e-ae51-161e38f3b8d9',)\n",
      "New Entity Key:  proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\n",
      "filename_uuid:  \n",
      "filename_uuid:  b3b5ad1c-560d-5916-9f21-74bbe39613c3\n",
      "2019-08-01 11:45:11,138 INFO sqlalchemy.engine.base.Engine INSERT INTO entities (id, name, location, \"generatedAtTime\", \"invalidatedAtTime\", comment, \"entityDescription_id\", \"classType\") VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,140 INFO sqlalchemy.engine.base.Engine ('7bfa14c7-17af-598e-ae51-161e38f3b8d9', 'proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz', '/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz', None, None, None, None, 'dataset')\n",
      "2019-08-01 11:45:11,141 INFO sqlalchemy.engine.base.Engine INSERT INTO \"datasetEntities\" (id) VALUES (?)\n",
      "2019-08-01 11:45:11,142 INFO sqlalchemy.engine.base.Engine ('7bfa14c7-17af-598e-ae51-161e38f3b8d9',)\n",
      "2019-08-01 11:45:11,144 INFO sqlalchemy.engine.base.Engine INSERT INTO \"wasAttributedTo\" (role, entity, agent) VALUES (?, ?, ?)\n",
      "2019-08-01 11:45:11,145 INFO sqlalchemy.engine.base.Engine (None, '7bfa14c7-17af-598e-ae51-161e38f3b8d9', 'CTAO')\n",
      "2019-08-01 11:45:11,149 INFO sqlalchemy.engine.base.Engine INSERT INTO used (role, time, activity_id, entity_id, \"usageDescription_id\") VALUES (?, ?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,151 INFO sqlalchemy.engine.base.Engine ('dl0.sub.evt', None, '4f0aac5b-8f39-453f-a8f6-9bac806c9fee', '7bfa14c7-17af-598e-ae51-161e38f3b8d9', None)\n",
      "2019-08-01 11:45:11,155 INFO sqlalchemy.engine.base.Engine SELECT count(*) AS count_1 \n",
      "FROM (SELECT \"datasetEntities\".id AS \"datasetEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities JOIN \"datasetEntities\" ON entities.id = \"datasetEntities\".id \n",
      "WHERE \"datasetEntities\".id = ?) AS anon_1\n",
      "2019-08-01 11:45:11,157 INFO sqlalchemy.engine.base.Engine ('b3b5ad1c-560d-5916-9f21-74bbe39613c3',)\n",
      "2019-08-01 11:45:11,164 INFO sqlalchemy.engine.base.Engine INSERT INTO \"wasAttributedTo\" (role, entity, agent) VALUES (?, ?, ?)\n",
      "2019-08-01 11:45:11,166 INFO sqlalchemy.engine.base.Engine (None, 'b3b5ad1c-560d-5916-9f21-74bbe39613c3', 'CTAO')\n",
      "2019-08-01 11:45:11,168 INFO sqlalchemy.engine.base.Engine INSERT INTO entities (id, name, location, \"generatedAtTime\", \"invalidatedAtTime\", comment, \"entityDescription_id\", \"classType\") VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,170 INFO sqlalchemy.engine.base.Engine (('b3b5ad1c-560d-5916-9f21-74bbe39613c3', 'muons.hdf5', '/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/muons.hdf5', None, None, None, None, 'dataset'), ('4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status', 'status', None, None, None, None, 'status', 'value'))\n",
      "2019-08-01 11:45:11,174 INFO sqlalchemy.engine.base.Engine INSERT INTO \"valueEntities\" (id, value) VALUES (?, ?)\n",
      "2019-08-01 11:45:11,178 INFO sqlalchemy.engine.base.Engine ('4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status', None)\n",
      "2019-08-01 11:45:11,180 INFO sqlalchemy.engine.base.Engine INSERT INTO \"datasetEntities\" (id) VALUES (?)\n",
      "2019-08-01 11:45:11,181 INFO sqlalchemy.engine.base.Engine ('b3b5ad1c-560d-5916-9f21-74bbe39613c3',)\n",
      "2019-08-01 11:45:11,183 INFO sqlalchemy.engine.base.Engine INSERT INTO \"wasGeneratedBy\" (role, activity_id, entity_id, \"generationDescription_id\") VALUES (?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,188 INFO sqlalchemy.engine.base.Engine ('dl1.tel.evt.muon', '4f0aac5b-8f39-453f-a8f6-9bac806c9fee', 'b3b5ad1c-560d-5916-9f21-74bbe39613c3', None)\n",
      "2019-08-01 11:45:11,191 INFO sqlalchemy.engine.base.Engine INSERT INTO \"wasGeneratedBy\" (role, activity_id, entity_id, \"generationDescription_id\") VALUES (?, ?, ?, ?)\n",
      "2019-08-01 11:45:11,193 INFO sqlalchemy.engine.base.Engine ('status', '4f0aac5b-8f39-453f-a8f6-9bac806c9fee', '4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status', None)\n",
      "2019-08-01 11:45:11,195 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import hashlib, uuid, os\n",
    "BLOCKSIZE = 65536\n",
    "hasher = hashlib.sha1()\n",
    "\n",
    "def get_file_id(url):\n",
    "    '''\n",
    "    # Computation of the hash of the file to determine the id of it\n",
    "    with open(cta_input['url'], 'rb') as afile:\n",
    "        buf = afile.read(BLOCKSIZE)\n",
    "        while len(buf) > 0:\n",
    "            hasher.update(buf)\n",
    "            buf = afile.read(BLOCKSIZE)\n",
    "            return hasher.hexdigest()\n",
    "    '''\n",
    "    logical_name = url.split('/')[-1] \n",
    "    name = logical_name + str(os.path.getctime(url))\n",
    "    file_uuid = str(uuid.uuid5(uuid.NAMESPACE_URL, name))\n",
    "    if session.query(DatasetEntity).filter(DatasetEntity.id==file_uuid).count():\n",
    "        print (\"Existing Entity Key: \", logical_name)\n",
    "        return file_uuid\n",
    "    else:\n",
    "        print (\"New Entity Key: \", logical_name)\n",
    "        return \"\"\n",
    "\n",
    "    # universal unique id\n",
    "    #return uuid.uuid4()\n",
    "\n",
    "def set_file_id(url):\n",
    "    logical_name = url.split('/')[-1] \n",
    "    name = logical_name + str(os.path.getctime(url))\n",
    "    file_uuid = str(uuid.uuid5(uuid.NAMESPACE_URL, name))\n",
    "    return file_uuid\n",
    "\n",
    "def add_activity(session, cta_activity):\n",
    "    if not (session.query(Activity).filter(Activity.id==cta_activity['activity_uuid']).count()): # for the tests\n",
    "        current_activity = Activity(id=cta_activity['activity_uuid'])\n",
    "        current_activity.name=cta_activity['activity_name']\n",
    "        current_activity.startTime=cta_activity['start']['time_utc']\n",
    "        current_activity.endTime=cta_activity['stop']['time_utc']\n",
    "        current_activity.comment=''\n",
    "        current_activity.activityDescription_id=cta_activity['activity_name']+'_'+cta_activity['system']['ctapipe_version']\n",
    "        session.add(current_activity)\n",
    "    \n",
    "        # Association with the agent\n",
    "        wAW = WasAssociatedWith()\n",
    "        wAW.activity = cta_activity['activity_uuid']\n",
    "        wAW.agent    = \"CTAO\"\n",
    "        #wAW.role = ?\n",
    "        session.add(wAW)\n",
    "\n",
    "# CTAO Agent\n",
    "CTA_org = \"CTAO\"\n",
    "agent = Agent(id=CTA_org)\n",
    "if session.query(Agent).filter(Agent.id==CTA_org).count():\n",
    "    print (\"Existing Agent Key: \", CTA_org)\n",
    "    pass\n",
    "else:\n",
    "    agent.name =\"CTA Observatory\"\n",
    "    agent.type = \"Organization\"\n",
    "    session.add(agent)\n",
    "\n",
    "# For each activity\n",
    "for cta_activity in p.provenance[:-1]:\n",
    "    add_activity(session, cta_activity)\n",
    "    \n",
    "    # For each input file\n",
    "    for cta_input in cta_activity['input']:\n",
    "        \n",
    "        # Get the id of the file\n",
    "        filename_uuid = get_file_id(cta_input['url'])\n",
    "        print (\"filename_uuid: \", filename_uuid)\n",
    "            \n",
    "        # If Entity does not exist in the database, add it - current_input_file.entityDescription_id= ???\n",
    "        if filename_uuid == \"\":\n",
    "            filename_uuid = set_file_id(cta_input['url'])\n",
    "            current_input_file = DatasetEntity(id=filename_uuid, classType = 'dataset', \\\n",
    "                                    name = cta_input['url'].split('/')[-1], location = cta_input['url'])\n",
    "            session.add(current_input_file)\n",
    "            \n",
    "        # Attribution to the agent - wAT.role = ?\n",
    "        wAT = WasAttributedTo(entity = filename_uuid, agent = \"CTAO\")\n",
    "        session.add(wAT)\n",
    "            \n",
    "        # Add the Used relationship\n",
    "        used1 = Used(role = cta_input['role'], activity_id = cta_activity['activity_uuid'], entity_id = filename_uuid) # incremental id\n",
    "        session.add(used1)\n",
    "    \n",
    "    # For each output file\n",
    "    for cta_output in cta_activity['output']:\n",
    "        \n",
    "        # Computation of the hash of the file to determine the id of it\n",
    "        filename_uuid = set_file_id(cta_output['url'])\n",
    "        print (\"filename_uuid: \", filename_uuid)\n",
    "            \n",
    "        # If Entity already exists in the database, raise an Exception or a error message - #current_output_file.entityDescription_id= ???\n",
    "        if session.query(DatasetEntity).filter(DatasetEntity.id==filename_uuid).count():\n",
    "            print (\"ERROR\")\n",
    "        else:\n",
    "            current_output_file = DatasetEntity(id=filename_uuid, classType = 'dataset', name = cta_output['url'].split('/')[-1],\\\n",
    "                                               location = cta_output['url'])\n",
    "            session.add(current_output_file)\n",
    "            \n",
    "            # Attribution to the agent - wAT.role = ?\n",
    "            wAT = WasAttributedTo(entity = filename_uuid, agent = \"CTAO\")\n",
    "            session.add(wAT)\n",
    "            \n",
    "        # Add the wasgeneratedBy relationship - incremental id\n",
    "        wGB1 = WasGeneratedBy(role = cta_output['role'], activity_id = cta_activity['activity_uuid'],\\\n",
    "                             entity_id = filename_uuid) \n",
    "        session.add(wGB1)\n",
    "        \n",
    "    # Add the status as an output ValueEntity\n",
    "    current_output_value = ValueEntity(id=cta_activity['activity_uuid']+'_status')\n",
    "    current_output_value.name = 'status'\n",
    "    current_output_value.classType = 'value'\n",
    "    current_output_value.valueXX = cta_activity['status']\n",
    "    current_output_value.entityDescription_id = 'status'\n",
    "    #current_output_value.location\n",
    "    #current_output_value.entityDescription_id= ???\n",
    "    session.add(current_output_value)\n",
    "    \n",
    "    # Add the wasgeneratedBy relationship - incremental id\n",
    "    wGB2 = WasGeneratedBy(role = 'status', activity_id = cta_activity['activity_uuid'],\\\n",
    "                             entity_id = cta_activity['activity_uuid']+'_status') \n",
    "    session.add(wGB2)\n",
    "        \n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the items of the database in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 11:45:17,707 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2019-08-01 11:45:17,709 INFO sqlalchemy.engine.base.Engine SELECT \"activityDescriptions\".id AS \"activityDescriptions_id\", \"activityDescriptions\".name AS \"activityDescriptions_name\", \"activityDescriptions\".version AS \"activityDescriptions_version\", \"activityDescriptions\".description AS \"activityDescriptions_description\", \"activityDescriptions\".type AS \"activityDescriptions_type\", \"activityDescriptions\".subtype AS \"activityDescriptions_subtype\", \"activityDescriptions\".doculink AS \"activityDescriptions_doculink\" \n",
      "FROM \"activityDescriptions\" ORDER BY \"activityDescriptions\".id\n",
      "2019-08-01 11:45:17,710 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,712 INFO sqlalchemy.engine.base.Engine SELECT \"entityDescriptions\".id AS \"entityDescriptions_id\", \"entityDescriptions\".name AS \"entityDescriptions_name\", \"entityDescriptions\".type AS \"entityDescriptions_type\", \"entityDescriptions\".description AS \"entityDescriptions_description\", \"entityDescriptions\".doculink AS \"entityDescriptions_doculink\", \"entityDescriptions\".\"classType\" AS \"entityDescriptions_classType\" \n",
      "FROM \"entityDescriptions\" ORDER BY \"entityDescriptions\".id\n",
      "2019-08-01 11:45:17,713 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,716 INFO sqlalchemy.engine.base.Engine SELECT \"usageDescriptions\".id AS \"usageDescriptions_id\", \"usageDescriptions\".role AS \"usageDescriptions_role\", \"usageDescriptions\".description AS \"usageDescriptions_description\", \"usageDescriptions\".type AS \"usageDescriptions_type\", \"usageDescriptions\".multiplicity AS \"usageDescriptions_multiplicity\", \"usageDescriptions\".\"activityDescription_id\" AS \"usageDescriptions_activityDescription_id\", \"usageDescriptions\".\"entityDescription_id\" AS \"usageDescriptions_entityDescription_id\" \n",
      "FROM \"usageDescriptions\" ORDER BY \"usageDescriptions\".id\n",
      "2019-08-01 11:45:17,716 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,718 INFO sqlalchemy.engine.base.Engine SELECT \"generationDescriptions\".id AS \"generationDescriptions_id\", \"generationDescriptions\".role AS \"generationDescriptions_role\", \"generationDescriptions\".description AS \"generationDescriptions_description\", \"generationDescriptions\".type AS \"generationDescriptions_type\", \"generationDescriptions\".multiplicity AS \"generationDescriptions_multiplicity\", \"generationDescriptions\".\"activityDescription_id\" AS \"generationDescriptions_activityDescription_id\", \"generationDescriptions\".\"entityDescription_id\" AS \"generationDescriptions_entityDescription_id\" \n",
      "FROM \"generationDescriptions\" ORDER BY \"generationDescriptions\".id\n",
      "2019-08-01 11:45:17,719 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,721 INFO sqlalchemy.engine.base.Engine SELECT \"datasetDescriptions\".id AS \"datasetDescriptions_id\", \"entityDescriptions\".id AS \"entityDescriptions_id\", \"entityDescriptions\".name AS \"entityDescriptions_name\", \"entityDescriptions\".type AS \"entityDescriptions_type\", \"entityDescriptions\".description AS \"entityDescriptions_description\", \"entityDescriptions\".doculink AS \"entityDescriptions_doculink\", \"entityDescriptions\".\"classType\" AS \"entityDescriptions_classType\", \"datasetDescriptions\".\"contentType\" AS \"datasetDescriptions_contentType\" \n",
      "FROM \"entityDescriptions\" JOIN \"datasetDescriptions\" ON \"entityDescriptions\".id = \"datasetDescriptions\".id ORDER BY \"datasetDescriptions\".id\n",
      "2019-08-01 11:45:17,722 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,726 INFO sqlalchemy.engine.base.Engine SELECT \"valueDescriptions\".id AS \"valueDescriptions_id\", \"entityDescriptions\".id AS \"entityDescriptions_id\", \"entityDescriptions\".name AS \"entityDescriptions_name\", \"entityDescriptions\".type AS \"entityDescriptions_type\", \"entityDescriptions\".description AS \"entityDescriptions_description\", \"entityDescriptions\".doculink AS \"entityDescriptions_doculink\", \"entityDescriptions\".\"classType\" AS \"entityDescriptions_classType\", \"valueDescriptions\".\"valueType\" AS \"valueDescriptions_valueType\", \"valueDescriptions\".unit AS \"valueDescriptions_unit\", \"valueDescriptions\".ucd AS \"valueDescriptions_ucd\", \"valueDescriptions\".utype AS \"valueDescriptions_utype\", \"valueDescriptions\".min AS \"valueDescriptions_min\", \"valueDescriptions\".max AS \"valueDescriptions_max\", \"valueDescriptions\".\"default\" AS \"valueDescriptions_default\", \"valueDescriptions\".options AS \"valueDescriptions_options\" \n",
      "FROM \"entityDescriptions\" JOIN \"valueDescriptions\" ON \"entityDescriptions\".id = \"valueDescriptions\".id ORDER BY \"valueDescriptions\".id\n",
      "2019-08-01 11:45:17,728 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,732 INFO sqlalchemy.engine.base.Engine SELECT \"parameterDescriptions\".id AS \"parameterDescriptions_id\", \"parameterDescriptions\".name AS \"parameterDescriptions_name\", \"parameterDescriptions\".\"valueType\" AS \"parameterDescriptions_valueType\", \"parameterDescriptions\".unit AS \"parameterDescriptions_unit\", \"parameterDescriptions\".ucd AS \"parameterDescriptions_ucd\", \"parameterDescriptions\".utype AS \"parameterDescriptions_utype\", \"parameterDescriptions\".min AS \"parameterDescriptions_min\", \"parameterDescriptions\".max AS \"parameterDescriptions_max\", \"parameterDescriptions\".options AS \"parameterDescriptions_options\", \"parameterDescriptions\".\"default\" AS \"parameterDescriptions_default\", \"parameterDescriptions\".description AS \"parameterDescriptions_description\" \n",
      "FROM \"parameterDescriptions\" ORDER BY \"parameterDescriptions\".id\n",
      "2019-08-01 11:45:17,732 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,734 INFO sqlalchemy.engine.base.Engine SELECT activities.id AS activities_id, activities.name AS activities_name, activities.\"startTime\" AS \"activities_startTime\", activities.\"endTime\" AS \"activities_endTime\", activities.comment AS activities_comment, activities.\"activityDescription_id\" AS \"activities_activityDescription_id\" \n",
      "FROM activities ORDER BY activities.id\n",
      "2019-08-01 11:45:17,734 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,737 INFO sqlalchemy.engine.base.Engine SELECT entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities ORDER BY entities.id\n",
      "2019-08-01 11:45:17,739 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,744 INFO sqlalchemy.engine.base.Engine SELECT used.id AS used_id, used.role AS used_role, used.time AS used_time, used.activity_id AS used_activity_id, used.entity_id AS used_entity_id, used.\"usageDescription_id\" AS \"used_usageDescription_id\" \n",
      "FROM used ORDER BY used.id\n",
      "2019-08-01 11:45:17,744 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,749 INFO sqlalchemy.engine.base.Engine SELECT \"wasGeneratedBy\".id AS \"wasGeneratedBy_id\", \"wasGeneratedBy\".role AS \"wasGeneratedBy_role\", \"wasGeneratedBy\".activity_id AS \"wasGeneratedBy_activity_id\", \"wasGeneratedBy\".entity_id AS \"wasGeneratedBy_entity_id\", \"wasGeneratedBy\".\"generationDescription_id\" AS \"wasGeneratedBy_generationDescription_id\" \n",
      "FROM \"wasGeneratedBy\" ORDER BY \"wasGeneratedBy\".id\n",
      "2019-08-01 11:45:17,752 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,754 INFO sqlalchemy.engine.base.Engine SELECT \"datasetEntities\".id AS \"datasetEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities JOIN \"datasetEntities\" ON entities.id = \"datasetEntities\".id ORDER BY \"datasetEntities\".id\n",
      "2019-08-01 11:45:17,755 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,760 INFO sqlalchemy.engine.base.Engine SELECT \"valueEntities\".id AS \"valueEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\", \"valueEntities\".value AS \"valueEntities_value\" \n",
      "FROM entities JOIN \"valueEntities\" ON entities.id = \"valueEntities\".id ORDER BY \"valueEntities\".id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 11:45:17,760 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,767 INFO sqlalchemy.engine.base.Engine SELECT parameters.id AS parameters_id, parameters.value AS parameters_value, parameters.name AS parameters_name, parameters.\"parameterDescription_id\" AS \"parameters_parameterDescription_id\" \n",
      "FROM parameters ORDER BY parameters.id\n",
      "2019-08-01 11:45:17,769 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,771 INFO sqlalchemy.engine.base.Engine SELECT agents.id AS agents_id, agents.name AS agents_name, agents.type AS agents_type, agents.email AS agents_email, agents.affiliation AS agents_affiliation, agents.phone AS agents_phone, agents.address AS agents_address, agents.comment AS agents_comment, agents.url AS agents_url \n",
      "FROM agents ORDER BY agents.id\n",
      "2019-08-01 11:45:17,773 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,776 INFO sqlalchemy.engine.base.Engine SELECT \"wasAttributedTo\".id AS \"wasAttributedTo_id\", \"wasAttributedTo\".role AS \"wasAttributedTo_role\", \"wasAttributedTo\".entity AS \"wasAttributedTo_entity\", \"wasAttributedTo\".agent AS \"wasAttributedTo_agent\" \n",
      "FROM \"wasAttributedTo\" ORDER BY \"wasAttributedTo\".id\n",
      "2019-08-01 11:45:17,777 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:17,783 INFO sqlalchemy.engine.base.Engine SELECT \"wasAssociatedWith\".id AS \"wasAssociatedWith_id\", \"wasAssociatedWith\".role AS \"wasAssociatedWith_role\", \"wasAssociatedWith\".activity AS \"wasAssociatedWith_activity\", \"wasAssociatedWith\".agent AS \"wasAssociatedWith_agent\" \n",
      "FROM \"wasAssociatedWith\" ORDER BY \"wasAssociatedWith\".id\n",
      "2019-08-01 11:45:17,784 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "# Put the results in a file for the Provenance RFC\n",
    "with open(\"muons_provRFC.txt\", \"w\") as prov:\n",
    "    prov.write(\"Provenance working example - CTA ctapipe-display-muons\\n\")\n",
    "    prov.write(\"datamodel version 1.2 / preparation for PR-version 2 January 2019. MS.\\n\")\n",
    "    prov.write(\"=========================================================================\\n\")\n",
    "    prov.write(\"Remarks\\n\")\n",
    "    prov.write(\"- ActivityDescription id = activity_name + '_' + ctapipe version\\n\")\n",
    "    prov.write(\"- Activity id = uuid returned from ctapipe\\n\")  \n",
    "    prov.write(\"- Entity id = hash (file)\\n\")\n",
    "    prov.write(\"- Link between Entity and EntityDescription not defined. Via role?\\n\")\n",
    "    prov.write(\"- Used and WasGeneratedBy Ids = activity id + '_' + 'entity id or incremental?\\n\")\n",
    "    prov.write(\"\\n\")\n",
    "    prov.write(\"\\n\")\n",
    "    prov.write(\"=========================================================================\\n\")\n",
    "    prov.write(\"\\n\")\n",
    "\n",
    "    # Opérations sur le fichier\n",
    "    for classname in [ActivityDescription, EntityDescription, UsageDescription, GenerationDescription, \\\n",
    "                      DatasetDescription, ValueDescription, ParameterDescription,\\\n",
    "                      Activity, Entity, Used, WasGeneratedBy, \\\n",
    "                      DatasetEntity, ValueEntity, Parameter,\\\n",
    "                      Agent, WasAttributedTo, WasAssociatedWith]:\n",
    "        for instance in session.query(classname).order_by(classname.id):\n",
    "            prov.write(\"%s\\n\" %instance)\n",
    "prov.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provenance working example - CTA ctapipe-display-muons\n",
      "datamodel version 1.2 / preparation for PR-version 2 January 2019. MS.\n",
      "=========================================================================\n",
      "Remarks\n",
      "- ActivityDescription id = activity_name + '_' + ctapipe version\n",
      "- Activity id = uuid returned from ctapipe\n",
      "- Entity id = hash (file)\n",
      "- Link between Entity and EntityDescription not defined. Via role?\n",
      "- Used and WasGeneratedBy Ids = activity id + '_' + 'entity id or incremental?\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "\n",
      "ActivityDescription.id=ctapipe_display_muons_0.6.1\n",
      "ActivityDescription.name=ctapipe_display_muons\n",
      "ActivityDescription.version=0.6.1\n",
      "ActivityDescription.description=None\n",
      "ActivityDescription.type=reconstruction\n",
      "ActivityDescription.subtype=\n",
      "ActivityDescription.doculink=\n",
      "\n",
      "DatasetDescription.id=muons_hdf5\n",
      "DatasetDescription.name=muons\n",
      "DatasetDescription.type=None\n",
      "DatasetDescription.description=muon file\n",
      "DatasetDescription.doculink=None\n",
      "DatasetDescription.classType=datasetDescription\n",
      "\n",
      "DatasetDescription.id=proton_events\n",
      "DatasetDescription.name=protons\n",
      "DatasetDescription.type=None\n",
      "DatasetDescription.description=proton file\n",
      "DatasetDescription.doculink=None\n",
      "DatasetDescription.classType=datasetDescription\n",
      "\n",
      "ValueDescription.id=status\n",
      "ValueDescription.name=None\n",
      "ValueDescription.type=None\n",
      "ValueDescription.description=None\n",
      "ValueDescription.doculink=None\n",
      "ValueDescription.classType=valueDescription\n",
      "\n",
      "UsageDescription.id=ctapipe_display_muons_0.6.1_proton_events\n",
      "UsageDescription.role=dl0.sub.evt\n",
      "UsageDescription.description=None\n",
      "UsageDescription.type=None\n",
      "UsageDescription.activityDescription_id=ctapipe_display_muons_0.6.1\n",
      "UsageDescription.entityDescription_id=proton_events\n",
      "\n",
      "GenerationDescription.id=ctapipe_display_muons_0.6.1_muons_hdf5\n",
      "GenerationDescription.role=dl0.sub.evt\n",
      "GenerationDescription.description=None\n",
      "GenerationDescription.type=None\n",
      "GenerationDescription.activityDescription_id=ctapipe_display_muons_0.6.1\n",
      "GenerationDescription.entityDescription_id=muons_hdf5\n",
      "\n",
      "GenerationDescription.id=ctapipe_display_muons_0.6.1_status\n",
      "GenerationDescription.role=quality\n",
      "GenerationDescription.description=None\n",
      "GenerationDescription.type=None\n",
      "GenerationDescription.activityDescription_id=ctapipe_display_muons_0.6.1\n",
      "GenerationDescription.entityDescription_id=status\n",
      "\n",
      "DatasetDescription.id=muons_hdf5\n",
      "DatasetDescription.name=muons\n",
      "DatasetDescription.type=None\n",
      "DatasetDescription.description=muon file\n",
      "DatasetDescription.doculink=None\n",
      "DatasetDescription.classType=datasetDescription\n",
      "\n",
      "DatasetDescription.id=proton_events\n",
      "DatasetDescription.name=protons\n",
      "DatasetDescription.type=None\n",
      "DatasetDescription.description=proton file\n",
      "DatasetDescription.doculink=None\n",
      "DatasetDescription.classType=datasetDescription\n",
      "\n",
      "ValueDescription.id=status\n",
      "ValueDescription.name=None\n",
      "ValueDescription.type=None\n",
      "ValueDescription.description=None\n",
      "ValueDescription.doculink=None\n",
      "ValueDescription.classType=valueDescription\n",
      "\n",
      "Activity.id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee\n",
      "Activity.name=ctapipe-reconstruct-muons\n",
      "Activity.startTime=2019-08-01T09:44:51.529\n",
      "Activity.endTime=2019-08-01T09:44:54.396\n",
      "Activity.comment=\n",
      "Activity.activityDescription_id=ctapipe-reconstruct-muons_0.5.2.post756+git93dae3f\n",
      "\n",
      "ValueEntity.id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status\n",
      "ValueEntity.classType=value\n",
      "ValueEntity.name=status\n",
      "ValueEntity.location=None\n",
      "ValueEntity.generatedAtTime=None\n",
      "ValueEntity.invalidatedAtTime=None\n",
      "ValueEntity.comment=None\n",
      "ValueEntity.classType=value\n",
      "ValueEntity.entityDescription_id=status\n",
      "\n",
      "DatasetEntity.id=7bfa14c7-17af-598e-ae51-161e38f3b8d9\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.name=proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\n",
      "DatasetEntity.location=/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\n",
      "DatasetEntity.generatedAtTime=None\n",
      "DatasetEntity.invalidatedAtTime=None\n",
      "DatasetEntity.comment=None\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.entityDescription_id=None\n",
      "\n",
      "DatasetEntity.id=b3b5ad1c-560d-5916-9f21-74bbe39613c3\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.name=muons.hdf5\n",
      "DatasetEntity.location=/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/muons.hdf5\n",
      "DatasetEntity.generatedAtTime=None\n",
      "DatasetEntity.invalidatedAtTime=None\n",
      "DatasetEntity.comment=None\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.entityDescription_id=None\n",
      "\n",
      "Used.id=1\n",
      "Used.role=dl0.sub.evt\n",
      "Used.time=None\n",
      "Used.activity_id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee\n",
      "Used.entity_id=7bfa14c7-17af-598e-ae51-161e38f3b8d9\n",
      "Used.usageDescription_id=None\n",
      "\n",
      "WasGeneratedBy.id=1\n",
      "WasGeneratedBy.role=dl1.tel.evt.muon\n",
      "WasGeneratedBy.activity_id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee\n",
      "WasGeneratedBy.entity_id=b3b5ad1c-560d-5916-9f21-74bbe39613c3\n",
      "WasGeneratedBy.generationDescription_id=None\n",
      "\n",
      "WasGeneratedBy.id=2\n",
      "WasGeneratedBy.role=status\n",
      "WasGeneratedBy.activity_id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee\n",
      "WasGeneratedBy.entity_id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status\n",
      "WasGeneratedBy.generationDescription_id=None\n",
      "\n",
      "DatasetEntity.id=7bfa14c7-17af-598e-ae51-161e38f3b8d9\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.name=proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\n",
      "DatasetEntity.location=/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/proton_20deg_180deg_run22___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\n",
      "DatasetEntity.generatedAtTime=None\n",
      "DatasetEntity.invalidatedAtTime=None\n",
      "DatasetEntity.comment=None\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.entityDescription_id=None\n",
      "\n",
      "DatasetEntity.id=b3b5ad1c-560d-5916-9f21-74bbe39613c3\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.name=muons.hdf5\n",
      "DatasetEntity.location=/Users/bourgeat/Documents/CTA/Provenance/ctasoft/improve-tool/ctapipe/prov_tests/muons.hdf5\n",
      "DatasetEntity.generatedAtTime=None\n",
      "DatasetEntity.invalidatedAtTime=None\n",
      "DatasetEntity.comment=None\n",
      "DatasetEntity.classType=dataset\n",
      "DatasetEntity.entityDescription_id=None\n",
      "\n",
      "ValueEntity.id=4f0aac5b-8f39-453f-a8f6-9bac806c9fee_status\n",
      "ValueEntity.classType=value\n",
      "ValueEntity.name=status\n",
      "ValueEntity.location=None\n",
      "ValueEntity.generatedAtTime=None\n",
      "ValueEntity.invalidatedAtTime=None\n",
      "ValueEntity.comment=None\n",
      "ValueEntity.classType=value\n",
      "ValueEntity.entityDescription_id=status\n",
      "\n",
      "Agent.id=CTAO\n",
      "Agent.name=CTA Observatory\n",
      "Agent.type=Organization\n",
      "Agent.email=None\n",
      "Agent.affiliation=None\n",
      "Agent.phone=None\n",
      "Agent.address=None\n",
      "Agent.comment=None\n",
      "Agent.url=None\n",
      "\n",
      "WasAttributedTo.id=1\n",
      "WasAttributedTo.entity=7bfa14c7-17af-598e-ae51-161e38f3b8d9\n",
      "WasAttributedTo.agent=CTAO\n",
      "WasAttributedTo.role=None\n",
      "\n",
      "WasAttributedTo.id=2\n",
      "WasAttributedTo.entity=b3b5ad1c-560d-5916-9f21-74bbe39613c3\n",
      "WasAttributedTo.agent=CTAO\n",
      "WasAttributedTo.role=None\n",
      "\n",
      "WasAssociatedWith.id=1\n",
      "WasAssociatedWith.activity=4f0aac5b-8f39-453f-a8f6-9bac806c9fee\n",
      "WasAssociatedWith.agent=CTAO\n",
      "WasAssociatedWith.role=None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the file contents\n",
    "with open(\"muons_provRFC.txt\", \"r\") as prov:\n",
    "    for line in prov:\n",
    "        print (line[:-1])\n",
    "prov.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 11:45:33,116 INFO sqlalchemy.engine.base.Engine SELECT activities.id AS activities_id, activities.name AS activities_name, activities.\"startTime\" AS \"activities_startTime\", activities.\"endTime\" AS \"activities_endTime\", activities.comment AS activities_comment, activities.\"activityDescription_id\" AS \"activities_activityDescription_id\" \n",
      "FROM activities ORDER BY activities.id\n",
      "2019-08-01 11:45:33,117 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,119 INFO sqlalchemy.engine.base.Engine SELECT entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities ORDER BY entities.id\n",
      "2019-08-01 11:45:33,119 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,121 INFO sqlalchemy.engine.base.Engine SELECT \"datasetEntities\".id AS \"datasetEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\" \n",
      "FROM entities JOIN \"datasetEntities\" ON entities.id = \"datasetEntities\".id ORDER BY \"datasetEntities\".id\n",
      "2019-08-01 11:45:33,121 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,123 INFO sqlalchemy.engine.base.Engine SELECT \"valueEntities\".id AS \"valueEntities_id\", entities.id AS entities_id, entities.name AS entities_name, entities.location AS entities_location, entities.\"generatedAtTime\" AS \"entities_generatedAtTime\", entities.\"invalidatedAtTime\" AS \"entities_invalidatedAtTime\", entities.comment AS entities_comment, entities.\"entityDescription_id\" AS \"entities_entityDescription_id\", entities.\"classType\" AS \"entities_classType\", \"valueEntities\".value AS \"valueEntities_value\" \n",
      "FROM entities JOIN \"valueEntities\" ON entities.id = \"valueEntities\".id ORDER BY \"valueEntities\".id\n",
      "2019-08-01 11:45:33,124 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,125 INFO sqlalchemy.engine.base.Engine SELECT used.id AS used_id, used.role AS used_role, used.time AS used_time, used.activity_id AS used_activity_id, used.entity_id AS used_entity_id, used.\"usageDescription_id\" AS \"used_usageDescription_id\" \n",
      "FROM used ORDER BY used.id\n",
      "2019-08-01 11:45:33,126 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,128 INFO sqlalchemy.engine.base.Engine SELECT \"wasGeneratedBy\".id AS \"wasGeneratedBy_id\", \"wasGeneratedBy\".role AS \"wasGeneratedBy_role\", \"wasGeneratedBy\".activity_id AS \"wasGeneratedBy_activity_id\", \"wasGeneratedBy\".entity_id AS \"wasGeneratedBy_entity_id\", \"wasGeneratedBy\".\"generationDescription_id\" AS \"wasGeneratedBy_generationDescription_id\" \n",
      "FROM \"wasGeneratedBy\" ORDER BY \"wasGeneratedBy\".id\n",
      "2019-08-01 11:45:33,128 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,130 INFO sqlalchemy.engine.base.Engine SELECT agents.id AS agents_id, agents.name AS agents_name, agents.type AS agents_type, agents.email AS agents_email, agents.affiliation AS agents_affiliation, agents.phone AS agents_phone, agents.address AS agents_address, agents.comment AS agents_comment, agents.url AS agents_url \n",
      "FROM agents ORDER BY agents.id\n",
      "2019-08-01 11:45:33,130 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,132 INFO sqlalchemy.engine.base.Engine SELECT \"wasAssociatedWith\".id AS \"wasAssociatedWith_id\", \"wasAssociatedWith\".role AS \"wasAssociatedWith_role\", \"wasAssociatedWith\".activity AS \"wasAssociatedWith_activity\", \"wasAssociatedWith\".agent AS \"wasAssociatedWith_agent\" \n",
      "FROM \"wasAssociatedWith\" ORDER BY \"wasAssociatedWith\".id\n",
      "2019-08-01 11:45:33,132 INFO sqlalchemy.engine.base.Engine ()\n",
      "2019-08-01 11:45:33,134 INFO sqlalchemy.engine.base.Engine SELECT \"wasAttributedTo\".id AS \"wasAttributedTo_id\", \"wasAttributedTo\".role AS \"wasAttributedTo_role\", \"wasAttributedTo\".entity AS \"wasAttributedTo_entity\", \"wasAttributedTo\".agent AS \"wasAttributedTo_agent\" \n",
      "FROM \"wasAttributedTo\" ORDER BY \"wasAttributedTo\".id\n",
      "2019-08-01 11:45:33,135 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "import  prov.model\n",
    "import  prov.dot\n",
    "\n",
    "provDoc = prov.model.ProvDocument()\n",
    "provDoc.add_namespace('voprov', 'http://wiki.ivoa.net/twiki/bin/view/IVOA/ProvenanceDataModel/ns/')\n",
    "provDoc.add_namespace('prov', 'http://www.w3.org/ns/prov/')\n",
    "provDoc.add_namespace('cta', 'http://voparis-cta-confluence.obspm.fr/provenance/')\n",
    "provFile = \"muons_provRFC.svg\"\n",
    "\n",
    "for classname in [Activity]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.activity('cta:' + instance.id, startTime=instance.startTime, endTime=instance.endTime)\n",
    "for classname in [Entity, DatasetEntity]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.entity('cta:' + str(instance.id), {'voprov:name':instance.name})\n",
    "for classname in [ValueEntity]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.entity('cta:' + str(instance.id), {'voprov:name':instance.name, 'voprov:value':instance.valueXX})\n",
    "for classname in [Used]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.used('cta:'+instance.activity_id, 'cta:'+str(instance.entity_id))\n",
    "for classname in [WasGeneratedBy]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.wasGeneratedBy('cta:'+str(instance.entity_id), 'cta:'+instance.activity_id)\n",
    "for classname in [Agent]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.agent('cta:'+instance.id)\n",
    "for classname in [WasAssociatedWith]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.wasAssociatedWith('cta:'+instance.activity, 'cta:'+instance.agent)\n",
    "for classname in [WasAttributedTo]:\n",
    "    for instance in session.query(classname).order_by(classname.id):\n",
    "        provDoc.wasAttributedTo('cta:'+instance.entity, 'cta:'+instance.agent)\n",
    "\n",
    "dot = prov.dot.prov_to_dot(provDoc, use_labels=True)\n",
    "dot.write_svg(provFile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the provenance \n",
    "<img src=\"muons_provRFC.svg?modified=1245678901\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-31 14:57:09,428 INFO sqlalchemy.engine.base.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
